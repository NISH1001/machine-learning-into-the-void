{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Representation\n",
    "Unlike images which are already available in terms of numbers, text are not inherently **numbers**. For any type of \n",
    "digital device to understand **anything**, things should be available in numbers because computers are \n",
    "\"computing\" devices, right? And hence, they process **numbers**.  \n",
    "\n",
    "For image, it's simple as manipulating pixels and then doing various levels of computations. But for texts (and textual \n",
    "data), the representation boils down to any of following things:\n",
    "- characters\n",
    "- words\n",
    "- sentences\n",
    "- paragraphs\n",
    "\n",
    "Things are a bit **not so easy** for textual data, since such data can be represented by any of the following forms. \n",
    "And also [Natural Language Processing](https://en.wikipedia.org/wiki/Natural_language_processing) is a bit of difficult \n",
    "domain itself, partly because textual representations are ambiguous and that human perceive linguistics in different \n",
    "forms.  \n",
    "\n",
    "For images, pixels combine to form abstract features, and such abstract features combine to form high-level features. \n",
    "The case is similar for textual data:\n",
    "- characters and symbols combine to form words\n",
    "- words combine to form phrases\n",
    "- phrases combine to form sentences\n",
    "- sentences combine to form paragraphs\n",
    "\n",
    "So, we can employ different representation techniques for extracting features from text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction in Text\n",
    "This is the most important part of any machine learning model. We extract features that are relevant and that can be understood by the computer/device. For a text, there are many things that \"features\" mean.\n",
    "\n",
    "Unlike, images that have pixels values already available as numeric data/features, texts have to be analyzed to extract features. Some of the things we can do is:\n",
    "- count the occurence of each word and use the counts as features\n",
    "- use one hot encoding scheme for a text (word/paragraph/document)\n",
    "- use techniques like tf-idf (term-frequency-inverse-document-frequency) which utilizes the rareness of the text itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding of Words\n",
    "First, let's convert words into features for a text. Here, we are doing label encoding of the words/tokens.  \n",
    "That is, we simply assign the index (id) number to each token/word in the given text.\n",
    "**Note**:  \n",
    "Token -> Word occuring in the text  \n",
    "Vocabulary -> Unique words in the given text or textual documents  \n",
    "<br/>\n",
    "A text is represented by a sequence of index ids which gives fixed-sized vector of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am paradox i am nish i love caffeine i love solving problems i am caffeine addict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_vocab(text):\n",
    "    \"\"\"\n",
    "        Just get unique tokens. \n",
    "        This is achieved through set() to remove duplicates\n",
    "    \"\"\"\n",
    "    return sorted(set(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['addict',\n",
       " 'am',\n",
       " 'caffeine',\n",
       " 'i',\n",
       " 'love',\n",
       " 'nish',\n",
       " 'paradox',\n",
       " 'problems',\n",
       " 'solving']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = get_vocab(text)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Unique Id for each vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_token_to_id(vocab):\n",
    "    \"\"\"\n",
    "        We loop from i to len(vocab).\n",
    "        And for each token/word in vocab, \n",
    "        we assign corresponding index number\n",
    "    \"\"\"\n",
    "    vocab = sorted(vocab) # just in case if vocab is not sorted\n",
    "    res = {}\n",
    "    for i, token in enumerate(vocab):\n",
    "        res[token] = i+1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'addict': 1,\n",
       " 'am': 2,\n",
       " 'caffeine': 3,\n",
       " 'i': 4,\n",
       " 'love': 5,\n",
       " 'nish': 6,\n",
       " 'paradox': 7,\n",
       " 'problems': 8,\n",
       " 'solving': 9}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary for mapping vocab token to id\n",
    "token_to_idx = map_token_to_id(vocab)\n",
    "token_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create id to token mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_id_to_token(token_to_idx):\n",
    "    \"\"\"\n",
    "        This is reverse of map_token_to_id\n",
    "    \"\"\"\n",
    "    return {idx:token for token, idx in token_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'addict',\n",
       " 2: 'am',\n",
       " 3: 'caffeine',\n",
       " 4: 'i',\n",
       " 5: 'love',\n",
       " 6: 'nish',\n",
       " 7: 'paradox',\n",
       " 8: 'problems',\n",
       " 9: 'solving'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create mapping from id to token for future use\n",
    "idx_to_token = map_id_to_token(token_to_idx)\n",
    "idx_to_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode each word from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text, token_to_idx):\n",
    "    \"\"\"\n",
    "        For each word/token in text, assign corresponding index number.\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    res = list(token_to_idx.keys())\n",
    "    for i, token in enumerate(res):\n",
    "        if token in tokens:\n",
    "            res[i] = token_to_idx[token]\n",
    "        else:\n",
    "            res[i] = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 4, 5, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = encode_text('i love paradox', token_to_idx)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([features], columns = vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addict</th>\n",
       "      <th>am</th>\n",
       "      <th>caffeine</th>\n",
       "      <th>i</th>\n",
       "      <th>love</th>\n",
       "      <th>nish</th>\n",
       "      <th>paradox</th>\n",
       "      <th>problems</th>\n",
       "      <th>solving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   addict  am  caffeine  i  love  nish  paradox  problems  solving\n",
       "0       0   0         0  4     5     0        7         0        0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find textual Similarity using label encoded text\n",
    "Let's test if two texts are similar with this encoding.  \n",
    "We are going to improve this using other encoding schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(v1, v2):\n",
    "    mag1 = np.linalg.norm(v1)\n",
    "    mag2 = np.linalg.norm(v2)\n",
    "    return np.dot(v1, v2)/(mag1 * mag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"i love problems\"\n",
    "text2 = \"i love to solving problems\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 4, 5, 0, 0, 8, 0]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1 = encode_text(text1, token_to_idx)\n",
    "features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 4, 5, 0, 0, 8, 9]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features2 = encode_text(text2, token_to_idx)\n",
    "features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([features1, features2], columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addict</th>\n",
       "      <th>am</th>\n",
       "      <th>caffeine</th>\n",
       "      <th>i</th>\n",
       "      <th>love</th>\n",
       "      <th>nish</th>\n",
       "      <th>paradox</th>\n",
       "      <th>problems</th>\n",
       "      <th>solving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   addict  am  caffeine  i  love  nish  paradox  problems  solving\n",
       "0       0   0         0  4     5     0        0         8        0\n",
       "1       0   0         0  4     5     0        0         8        9"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7513428837969107"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cosine_similarity(features1, features2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "This is similar to label encoding. Instead of using **index** number, we are simply going to use boolean values 1/0 \n",
    "to represent the presence or absence of token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am paradox I am Nish i love caffeine i love solving problems i am caffeine addict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "text = text.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['addict',\n",
       " 'am',\n",
       " 'caffeine',\n",
       " 'i',\n",
       " 'love',\n",
       " 'nish',\n",
       " 'paradox',\n",
       " 'problems',\n",
       " 'solving']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = get_vocab(text)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'addict': 1,\n",
       " 'am': 2,\n",
       " 'caffeine': 3,\n",
       " 'i': 4,\n",
       " 'love': 5,\n",
       " 'nish': 6,\n",
       " 'paradox': 7,\n",
       " 'problems': 8,\n",
       " 'solving': 9}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_idx = map_token_to_id(vocab)\n",
    "token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text2(text, token_to_idx):\n",
    "    tokens = text.split()\n",
    "    res = list(token_to_idx.keys())\n",
    "    # loop  through each token in vocab\n",
    "    # and check if the vocab token is in our text\n",
    "    # if present, we put 1, else 0\n",
    "    for i, token in enumerate(res):\n",
    "        if token not in tokens:\n",
    "            res[i] = 0\n",
    "        else:\n",
    "            res[i] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"i love problems\"\n",
    "text2 = \"i love caffeine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0, 0, 1, 1, 0, 0, 1, 0], [0, 0, 1, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1 = encode_text2(text1, token_to_idx)\n",
    "features2 = encode_text2(text2, token_to_idx)\n",
    "features1, features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([features1, features2], columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addict</th>\n",
       "      <th>am</th>\n",
       "      <th>caffeine</th>\n",
       "      <th>i</th>\n",
       "      <th>love</th>\n",
       "      <th>nish</th>\n",
       "      <th>paradox</th>\n",
       "      <th>problems</th>\n",
       "      <th>solving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   addict  am  caffeine  i  love  nish  paradox  problems  solving\n",
       "0       0   0         0  1     1     0        0         1        0\n",
       "1       0   0         1  1     1     0        0         0        0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666667"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cosine_similarity(features1, features2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Based Encoding\n",
    "While one-hot encoding works most of the time, it does not give any information regarding the strengths provided by \n",
    "the frequency of each word in the text. So, count vectorizer takes into account the frequency of the word in the text.  \n",
    "So, here we have to create a mapping of word and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am paradox I am Nish i love caffeine i love solving problems i am caffeine addict\".lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_map(text):\n",
    "    tokens = text.split()\n",
    "    c = Counter(tokens)\n",
    "    return dict(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 5,\n",
       " 'am': 3,\n",
       " 'paradox': 1,\n",
       " 'nish': 1,\n",
       " 'love': 2,\n",
       " 'caffeine': 2,\n",
       " 'solving': 1,\n",
       " 'problems': 1,\n",
       " 'addict': 1}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_map = get_frequency_map(text)\n",
    "frequency_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['addict',\n",
       " 'am',\n",
       " 'caffeine',\n",
       " 'i',\n",
       " 'love',\n",
       " 'nish',\n",
       " 'paradox',\n",
       " 'problems',\n",
       " 'solving']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = get_vocab(text)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'addict': 1,\n",
       " 'am': 2,\n",
       " 'caffeine': 3,\n",
       " 'i': 4,\n",
       " 'love': 5,\n",
       " 'nish': 6,\n",
       " 'paradox': 7,\n",
       " 'problems': 8,\n",
       " 'solving': 9}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_idx = map_token_to_id(vocab)\n",
    "token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text3(text, token_to_idx):\n",
    "    frequency_map = get_frequency_map(text)\n",
    "    tokens = text.split()\n",
    "    res = list(token_to_idx.keys())\n",
    "    # loop  through each token in vocab\n",
    "    # and check if the vocab token is in our text\n",
    "    # if present, we put corresponding count value\n",
    "    for i, token in enumerate(res):\n",
    "        if token in tokens and token in frequency_map:\n",
    "            res[i] = frequency_map[token]\n",
    "        else:\n",
    "            res[i] = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = encode_text3(text, token_to_idx)\n",
    "df = pd.DataFrame([features], columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addict</th>\n",
       "      <th>am</th>\n",
       "      <th>caffeine</th>\n",
       "      <th>i</th>\n",
       "      <th>love</th>\n",
       "      <th>nish</th>\n",
       "      <th>paradox</th>\n",
       "      <th>problems</th>\n",
       "      <th>solving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   addict  am  caffeine  i  love  nish  paradox  problems  solving\n",
       "0       1   3         2  5     2     1        1         1        1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"i love problems\"\n",
    "text2 = \"i love love caffeine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0, 0, 1, 1, 0, 0, 1, 0], [0, 0, 1, 1, 2, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1 = encode_text3(text1, token_to_idx)\n",
    "features2 = encode_text3(text2, token_to_idx)\n",
    "features1, features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([features1, features2], columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addict</th>\n",
       "      <th>am</th>\n",
       "      <th>caffeine</th>\n",
       "      <th>i</th>\n",
       "      <th>love</th>\n",
       "      <th>nish</th>\n",
       "      <th>paradox</th>\n",
       "      <th>problems</th>\n",
       "      <th>solving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   addict  am  caffeine  i  love  nish  paradox  problems  solving\n",
       "0       0   0         0  1     1     0        0         1        0\n",
       "1       0   0         1  1     2     0        0         0        0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067811865476"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cosine_similarity(features1, features2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scikit-Learn Vectorizer\n",
    "Since scikit learn already provides above encoding schemes, we can simply use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am paradox I am Nish i love caffeine i love solving problems i am caffeine addict\".lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'paradox',\n",
       " 'i',\n",
       " 'am',\n",
       " 'nish',\n",
       " 'i',\n",
       " 'love',\n",
       " 'caffeine',\n",
       " 'i',\n",
       " 'love',\n",
       " 'solving',\n",
       " 'problems',\n",
       " 'i',\n",
       " 'am',\n",
       " 'caffeine',\n",
       " 'addict']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "features = vectorizer.fit_transform(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['addict', 'am', 'caffeine', 'love', 'nish', 'paradox', 'problems', 'solving']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"caffeine is love\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (2, 3)\t1\n"
     ]
    }
   ],
   "source": [
    "features = vectorizer.transform(nltk.word_tokenize(test))\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(features, columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addict</th>\n",
       "      <th>am</th>\n",
       "      <th>caffeine</th>\n",
       "      <th>i</th>\n",
       "      <th>love</th>\n",
       "      <th>nish</th>\n",
       "      <th>paradox</th>\n",
       "      <th>problems</th>\n",
       "      <th>solving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   addict  am  caffeine  i  love  nish  paradox  problems  solving\n",
       "0       0   0         0  1     1     0        0         1        0\n",
       "1       0   0         1  1     2     0        0         0        0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
