{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "This is the most important part of any machine learning model. We extract features that are relevant and that can be understood by the computer/device. For a text, there are many things that **\"features\"** mean.  \n",
    "\n",
    "Unlike, images that have pixels values already available as numeric data/features, texts have to be analyzed to extract features. Some of the things we can do is:  \n",
    "- count the occurence of each word and use the counts as features\n",
    "- use one hot encoding scheme for a text (word/paragraph/document)\n",
    "- use techniques like **tf-idf** (term-frequency-inverse-document-frequency) which utilizes the rareness of the text itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document-Term Matrix\n",
    "\n",
    "This is nothing but the mapping of counts of each token/term in a document.  \n",
    "\n",
    "**What we can do:**  \n",
    "- extract all the relevant terms from each document along with the count\n",
    "- create a set of all the tokens from all the documents\n",
    "- now map each token from each document to the counts\n",
    "\n",
    "**Say we have 2 documents:**  \n",
    "- d1: \"i am paradox. i am gru\"\n",
    "- d2: \"i am nish\"\n",
    "\n",
    "### d1\n",
    "tokens: i, am, paradox, i, am, gru  \n",
    "**counts** \n",
    "i : 2\n",
    "am : 2\n",
    "paradox: 1\n",
    "gru: 1\n",
    "\n",
    "### d2\n",
    "tokens: i, am, nish\n",
    "**counts**  \n",
    "i: 1  \n",
    "am: 1  \n",
    "nish: 1  \n",
    "\n",
    "### generate vocabularies\n",
    "Here we create a set of all the **unique** tokens from all the documents.\n",
    "**tokens**  \n",
    "i, am, paradox, gru, nish\n",
    "\n",
    "### document-term matrix\n",
    "\n",
    "| document | i | am | paradox | gru | nish |\n",
    "| -------  |---|----|---------|-----|------|\n",
    "| d1       | 2 | 2  | 1       |1    |0     |\n",
    "| d2       | 1 | 1  | 0       |0    |1     |\n",
    "\n",
    "\n",
    "So, feature vector for the documents are as follows:  \n",
    "**d1** --> (2, 2, 1, 1, 0)  \n",
    "**d2** --> (1, 1, 0, 0, 1)  \n",
    "\n",
    "Finally, these vectors can be used for our machine learning model.  \n",
    "\n",
    "Cheers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"i am paradox. i am gru. i am nish. i am a caffeine addict.  i love caffeine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use simple counts as features\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's train the feature extractor on this simple training \"text\n",
    "tokens = nltk.word_tokenize(text)\n",
    "count_vectorizer = CountVectorizer().fit(tokens)\n",
    "count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['addict', 'am', 'caffeine', 'gru', 'love', 'nish', 'paradox']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the available features/tokens\n",
    "count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (2, 4)\t1\n"
     ]
    }
   ],
   "source": [
    "# let's test new document\n",
    "test = \"caffeine is love\"\n",
    "test_vect = count_vectorizer.transform(nltk.word_tokenize(test))\n",
    "print(test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get document-term matrix\n",
    "test_vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addict</th>\n",
       "      <th>am</th>\n",
       "      <th>caffeine</th>\n",
       "      <th>gru</th>\n",
       "      <th>love</th>\n",
       "      <th>nish</th>\n",
       "      <th>paradox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   addict  am  caffeine  gru  love  nish  paradox\n",
       "0       0   0         1    0     0     0        0\n",
       "1       0   0         0    0     0     0        0\n",
       "2       0   0         0    0     1     0        0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see what document-term matrix is under the hood\n",
    "pd.DataFrame(test_vect.toarray(), columns = count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try on more complex (real) text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Yes, it's hard to get things done, to accept stuff despite being seemingly unworthy.But hey! Worthiness is just our own abstraction of comfort.\", \"We should be able to embrace what life throws at us diligently. Being pedantic won't do good.\", 'As we are always governed by the vastness of entropy, as such we tend to be over-dramatic towards the minor things in life.', 'But, if we can pass that out, whether the withering wealth, health, love and shit, we can probably render ourselves joyous.', \"I think that's the way of living of life. Live. Don't just breathe.\"]\n",
      "['we seem to be living our life. but we are not']\n"
     ]
    }
   ],
   "source": [
    "train_docs = [\n",
    "    \"Yes, it's hard to get things done, to accept stuff despite being seemingly unworthy.But hey! Worthiness is just our own abstraction of comfort.\",\n",
    "    \"We should be able to embrace what life throws at us diligently. Being pedantic won't do good.\",\n",
    "    \"As we are always governed by the vastness of entropy, as such we tend to be over-dramatic towards the minor things in life.\",\n",
    "    \"But, if we can pass that out, whether the withering wealth, health, love and shit, we can probably render ourselves joyous.\",\n",
    "    \"I think that's the way of living of life. Live. Don't just breathe.\"\n",
    "]\n",
    "\n",
    "test_docs = [\n",
    "    \"we seem to be living our life. but we are not\"\n",
    "]\n",
    "print(train_docs)\n",
    "print(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'abstraction', 'accept', 'always', 'and', 'are', 'as', 'at', 'be', 'being', 'breathe', 'but', 'by', 'can', 'comfort', 'despite', 'diligently', 'do', 'don', 'done', 'dramatic', 'embrace', 'entropy', 'get', 'good', 'governed', 'hard', 'health', 'hey', 'if', 'in', 'is', 'it', 'joyous', 'just', 'life', 'live', 'living', 'love', 'minor', 'of', 'our', 'ourselves', 'out', 'over', 'own', 'pass', 'pedantic', 'probably', 'render', 'seemingly', 'shit', 'should', 'stuff', 'such', 'tend', 'that', 'the', 'things', 'think', 'throws', 'to', 'towards', 'unworthy', 'us', 'vastness', 'way', 'we', 'wealth', 'what', 'whether', 'withering', 'won', 'worthiness', 'yes']\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer().fit(train_docs)\n",
    "print(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0\n",
      "  0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vect = count_vectorizer.transform(test_docs)\n",
    "print(vect.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>abstraction</th>\n",
       "      <th>accept</th>\n",
       "      <th>always</th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>as</th>\n",
       "      <th>at</th>\n",
       "      <th>be</th>\n",
       "      <th>being</th>\n",
       "      <th>...</th>\n",
       "      <th>vastness</th>\n",
       "      <th>way</th>\n",
       "      <th>we</th>\n",
       "      <th>wealth</th>\n",
       "      <th>what</th>\n",
       "      <th>whether</th>\n",
       "      <th>withering</th>\n",
       "      <th>won</th>\n",
       "      <th>worthiness</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  abstraction  accept  always  and  are  as  at  be  being ...   \\\n",
       "0     0            0       0       0    0    1   0   0   1      0 ...    \n",
       "\n",
       "   vastness  way  we  wealth  what  whether  withering  won  worthiness  yes  \n",
       "0         0    0   2       0     0        0          0    0           0    0  \n",
       "\n",
       "[1 rows x 75 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vect.toarray(), columns=count_vectorizer.get_feature_names() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "Tf-idf stands for term frequency - inverse document frequency which is used in text mining and information retrieval system to evauluate how important a word is in a document.\n",
    "\n",
    "The importance is directly proportional to the number of times a word appears in the document but is also weighted down by the frequency of the word in the whole corpus.\n",
    "\n",
    "### Mathematically\n",
    "\n",
    "**term-frequency (tf)** of a term/word t is actually given by:\n",
    "\n",
    "`tf = (number of times the term t appears in a document ) / (total number of terms in the same document)`\n",
    "\n",
    "**inverse document frequency (idf)** mesaures how much rare a term is throughout the multiple documents.\n",
    "That is, more the rareness of a term, the greater we tend to value the rareness.\n",
    "\n",
    "`idf = natural_logarithm[ (total number of documents) / (number of documents having the term t) ]`\n",
    "\n",
    "Here, `natural_logarithm` is the logarithmic function with base **e**.\n",
    "\n",
    "\n",
    "Reference: https://github.com/NISH1001/tag-generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create tf-idf features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'abstraction', 'accept', 'always', 'and', 'are', 'as', 'at', 'be', 'being', 'breathe', 'but', 'by', 'can', 'comfort', 'despite', 'diligently', 'do', 'don', 'done', 'dramatic', 'embrace', 'entropy', 'get', 'good', 'governed', 'hard', 'health', 'hey', 'if', 'in', 'is', 'it', 'joyous', 'just', 'life', 'live', 'living', 'love', 'minor', 'of', 'our', 'ourselves', 'out', 'over', 'own', 'pass', 'pedantic', 'probably', 'render', 'seemingly', 'shit', 'should', 'stuff', 'such', 'tend', 'that', 'the', 'things', 'think', 'throws', 'to', 'towards', 'unworthy', 'us', 'vastness', 'way', 'we', 'wealth', 'what', 'whether', 'withering', 'won', 'worthiness', 'yes']\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer().fit(train_docs)\n",
    "print(tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.37815591\n",
      "  0.         0.         0.30509381 0.         0.         0.30509381\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.25325542\n",
      "  0.         0.37815591 0.         0.         0.         0.37815591\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25325542 0.         0.         0.         0.\n",
      "  0.         0.50651084 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "vect = tfidf_vectorizer.transform(test_docs)\n",
    "print(vect.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>abstraction</th>\n",
       "      <th>accept</th>\n",
       "      <th>always</th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>as</th>\n",
       "      <th>at</th>\n",
       "      <th>be</th>\n",
       "      <th>being</th>\n",
       "      <th>...</th>\n",
       "      <th>vastness</th>\n",
       "      <th>way</th>\n",
       "      <th>we</th>\n",
       "      <th>wealth</th>\n",
       "      <th>what</th>\n",
       "      <th>whether</th>\n",
       "      <th>withering</th>\n",
       "      <th>won</th>\n",
       "      <th>worthiness</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.378156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  abstraction  accept  always  and       are   as   at        be  \\\n",
       "0   0.0          0.0     0.0     0.0  0.0  0.378156  0.0  0.0  0.305094   \n",
       "\n",
       "   being ...   vastness  way        we  wealth  what  whether  withering  won  \\\n",
       "0    0.0 ...        0.0  0.0  0.506511     0.0   0.0      0.0        0.0  0.0   \n",
       "\n",
       "   worthiness  yes  \n",
       "0         0.0  0.0  \n",
       "\n",
       "[1 rows x 75 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vect.toarray(), columns=tfidf_vectorizer.get_feature_names() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
