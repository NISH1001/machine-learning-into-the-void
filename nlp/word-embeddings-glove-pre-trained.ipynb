{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GloVe\n",
    "The data is simple txt file in the format:  \n",
    "```\n",
    "word1 val1 val2 val3 ... valn\n",
    "word2 val1 val2 val3 ... valn\n",
    "...\n",
    "...\n",
    "wordk ...\n",
    "```\n",
    "Where,  \n",
    "wordi -> ith word in the vocab  \n",
    "val1, val2,... valn -> n-d vector for wordi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_PATH = \"/home/paradox/data/glove/glove.6B.50d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(path):\n",
    "    glove = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            tokens = line.split()\n",
    "            token = tokens[0]\n",
    "            vec = list(map(float, tokens[1:]))\n",
    "            glove[token] = np.array(vec)\n",
    "    return glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = load_embeddings(GLOVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['human'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50451 ,  0.68607 , -0.59517 , -0.022801,  0.60046 , -0.13498 ,\n",
       "       -0.08813 ,  0.47377 , -0.61798 , -0.31012 , -0.076666,  1.493   ,\n",
       "       -0.034189, -0.98173 ,  0.68229 ,  0.81722 , -0.51874 , -0.31503 ,\n",
       "       -0.55809 ,  0.66421 ,  0.1961  , -0.13495 , -0.11476 , -0.30344 ,\n",
       "        0.41177 , -2.223   , -1.0756  , -1.0783  , -0.34354 ,  0.33505 ,\n",
       "        1.9927  , -0.04234 , -0.64319 ,  0.71125 ,  0.49159 ,  0.16754 ,\n",
       "        0.34344 , -0.25663 , -0.8523  ,  0.1661  ,  0.40102 ,  1.1685  ,\n",
       "       -1.0137  , -0.21585 , -0.15155 ,  0.78321 , -0.91241 , -1.6106  ,\n",
       "       -0.64426 , -0.51042 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.37854  ,  1.8233   , -1.2648   , -0.1043   ,  0.35829  ,\n",
       "        0.60029  , -0.17538  ,  0.83767  , -0.056798 , -0.75795  ,\n",
       "        0.22681  ,  0.98587  ,  0.60587  , -0.31419  ,  0.28877  ,\n",
       "        0.56013  , -0.77456  ,  0.071421 , -0.5741   ,  0.21342  ,\n",
       "        0.57674  ,  0.3868   , -0.12574  ,  0.28012  ,  0.28135  ,\n",
       "       -1.8053   , -1.0421   , -0.19255  , -0.55375  , -0.054526 ,\n",
       "        1.5574   ,  0.39296  , -0.2475   ,  0.34251  ,  0.45365  ,\n",
       "        0.16237  ,  0.52464  , -0.070272 , -0.83744  , -1.0326   ,\n",
       "        0.45946  ,  0.25302  , -0.17837  , -0.73398  , -0.20025  ,\n",
       "        0.2347   , -0.56095  , -2.2839   ,  0.0092753, -0.60284  ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.8153e-01,  6.4827e-01, -5.8210e-01, -4.9451e-01,  1.5415e+00,\n",
       "        1.3450e+00, -4.3305e-01,  5.8059e-01,  3.5556e-01, -2.5184e-01,\n",
       "        2.0254e-01, -7.1643e-01,  3.0610e-01,  5.6127e-01,  8.3928e-01,\n",
       "       -3.8085e-01, -9.0875e-01,  4.3326e-01, -1.4436e-02,  2.3725e-01,\n",
       "       -5.3799e-01,  1.7773e+00, -6.6433e-02,  6.9795e-01,  6.9291e-01,\n",
       "       -2.6739e+00, -7.6805e-01,  3.3929e-01,  1.9695e-01, -3.5245e-01,\n",
       "        2.2920e+00, -2.7411e-01, -3.0169e-01,  8.5286e-04,  1.6923e-01,\n",
       "        9.1433e-02, -2.3610e-02,  3.6236e-02,  3.4488e-01, -8.3947e-01,\n",
       "       -2.5174e-01,  4.2123e-01,  4.8616e-01,  2.2325e-02,  5.5760e-01,\n",
       "       -8.5223e-01, -2.3073e-01, -1.3138e+00,  4.8764e-01, -1.0467e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.094386,  0.43007 , -0.17224 , -0.45529 ,  1.6447  ,  0.40335 ,\n",
       "       -0.37263 ,  0.25071 , -0.10588 ,  0.10778 , -0.10848 ,  0.15181 ,\n",
       "       -0.65396 ,  0.55054 ,  0.59591 , -0.46278 ,  0.11847 ,  0.64448 ,\n",
       "       -0.70948 ,  0.23947 , -0.82905 ,  1.272   ,  0.033021,  0.2935  ,\n",
       "        0.3911  , -2.8094  , -0.70745 ,  0.4106  ,  0.3894  , -0.2913  ,\n",
       "        2.6124  , -0.34576 , -0.16832 ,  0.25154 ,  0.31216 ,  0.31639 ,\n",
       "        0.12539 , -0.012646,  0.22297 , -0.56585 , -0.086264,  0.62549 ,\n",
       "       -0.0576  ,  0.29375 ,  0.66005 , -0.53115 , -0.48233 , -0.97925 ,\n",
       "        0.53135 , -0.11725 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['man']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Arithmetic\n",
    "With these vectors, we can do:  \n",
    "```\n",
    "king - man + woman = queen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = glove['king'] - glove['man'] + glove['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.417366  ,  0.90427   , -1.00503   , -0.062021  ,  0.49726   ,\n",
       "         0.80667   , -0.14855   ,  0.80365   , -0.15654   , -0.66974   ,\n",
       "         0.234354  ,  0.62476   ,  0.925871  , -0.971     ,  0.92566   ,\n",
       "         0.89915   , -1.54596   , -0.52625   ,  0.136954  ,  0.66199   ,\n",
       "         0.48716   ,  0.37035   , -0.214214  ,  0.10101   ,  0.71358   ,\n",
       "        -2.0875    , -1.1362    , -1.14961   , -0.53599   ,  0.2739    ,\n",
       "         1.6723    ,  0.02931   , -0.77656   ,  0.46056286,  0.34866   ,\n",
       "        -0.057417  ,  0.19444   , -0.207748  , -0.73039   , -0.10752   ,\n",
       "         0.235544  ,  0.96424   , -0.46994   , -0.487275  , -0.254     ,\n",
       "         0.46213   , -0.66081   , -1.94515   , -0.68797   , -0.49784   ]),\n",
       " (50,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### similarity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(v1, v2):\n",
    "    mag1 = np.linalg.norm(v1)\n",
    "    mag2 = np.linalg.norm(v2)\n",
    "    return np.dot(v1, v2)/(mag1*mag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_test(s1, s2):\n",
    "    v = np.zeros(50)\n",
    "    v1 = glove.get(s1, v)\n",
    "    v2 = glove.get(s2, v)\n",
    "    return compute_cosine_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8514841863412058"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_test('life', 'mind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Similar Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(word, embedding, top_n=5):\n",
    "    if word not in embedding:\n",
    "        return []\n",
    "    wvec = embedding[word]\n",
    "    result = []\n",
    "    s = 0\n",
    "    for w in embedding:\n",
    "        vec = embedding[w]\n",
    "        score = compute_cosine_similarity(wvec, vec)\n",
    "        result.append((score, w))\n",
    "    return sorted(result, key=lambda x: x[0], reverse=True)[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0000000000000002, 'queen'),\n",
       " (0.851516638750669, 'princess'),\n",
       " (0.8050609250765663, 'lady'),\n",
       " (0.7873042176943493, 'elizabeth'),\n",
       " (0.7839043010964117, 'king'),\n",
       " (0.7821860976090151, 'prince'),\n",
       " (0.7692777928548158, 'coronation'),\n",
       " (0.7626097498967261, 'consort'),\n",
       " (0.744286480167597, 'royal'),\n",
       " (0.7382649680186563, 'crown')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar('queen', glove, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Full Text/Document\n",
    "Since, word2vec and glove give vectors for single words, we can take the average of word vectors of words in the text \n",
    "to convert our text into a vector.  \n",
    "We are actually generating document vector here using word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec(text, ignore_case=True):\n",
    "    tokens = text.split()\n",
    "    n = 50\n",
    "    res = np.zeros(n)\n",
    "    for token in tokens:\n",
    "        token = token.lower() if ignore_case else token\n",
    "        vec = glove.get(token, [])\n",
    "        if len(vec):\n",
    "            res = res + glove[token]\n",
    "    return res/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395517877525256"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = doc2vec(\"located\")\n",
    "v2 = doc2vec(\"location of\")\n",
    "compute_cosine_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8547478507418468"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = doc2vec(\"sorry\")\n",
    "v2 = doc2vec(\"forgive me\")\n",
    "compute_cosine_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5366700279346573"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = doc2vec(\"queen\")\n",
    "v2 = doc2vec(\"man\")\n",
    "compute_cosine_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
