{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "It is one of the simplest machine learning model for text classification. It uses the probabilisti distribution of tokens/words (counts) to classify documents. It is based on infamous **Bayes Theorem** which goes like this:\n",
    "\n",
    "`Prob(B | A) = Prob(A | B) * Prob(B) / Prob(A)`\n",
    "\n",
    "Fair enough, right?\n",
    "\n",
    "## Text Classification\n",
    "Say we have Document **D** that belongs to class **C**. So, using bayes theorem we can infer:  \n",
    "\n",
    "`Prob(C | D) = Prob(D | C) * Prob(C) / Prob(D)`\n",
    "\n",
    "So far so good.  \n",
    "\n",
    "We know a document is made up of tokens (combination of tokens, commonly referred to as **ngram language model**):  \n",
    "`D = [d1, d2, d3, ...]`\n",
    "\n",
    "```bash\n",
    "Prob(C | D)\n",
    "= Prob(d1 | C) * Prob(d2 | C) * Prob(d3 | C) .... * Prob(C) / Prob(D)\n",
    "```\n",
    "\n",
    "Remember, we have seggregated Prob(D | C) to individual probabilities of individual tokens (ngrams) constituting\n",
    "document D. This is why Naive Bayes classifier is **Naive** - it assumes  each tokens are independent of each other.  \n",
    "  \n",
    "Think it of as two independent events **A** and **B**. So, what's the probability of both events occuring simultaneously?  \n",
    "`Prob(A, B) = Prob(A) * Prob(B)`\n",
    "\n",
    "Now we can infer the Probabities Prob(di | C) as :  \n",
    "` (count(di) that belongs to class C) / (total number of tokens)`\n",
    "\n",
    "### Putting Things Into Perspective\n",
    "And that is how we can find the probability of document **D** beloning to class **C** assuming independence \n",
    "of individual features(ngrams). \n",
    "\n",
    "Now, say we have classes:  \n",
    "C1, C2, C3, ...  \n",
    "\n",
    "\n",
    "And we want to classify a test document **D**. All we have to do is find the probabilty of this document **D**\n",
    "beloning to each of the classes. And we choose the class where **Prob(D | C)** is the highest.\n",
    "\n",
    "#### Training Steps (somewhat)\n",
    "It's nothing but counting the \"stuff\" that matter.\n",
    "- tokenize the documents for each classes\n",
    "- each token can be unigram, bigram, ...\n",
    "- extract features for each token -> counts or tf-idf\n",
    "\n",
    "#### Let's classify\n",
    "- extract features (count) for the document to be classified\n",
    "- calculate **Prob(C1 | D)**\n",
    "- Calculate **Prob(C2 | D)**\n",
    "- Calculate **Prob(C3 | D)**\n",
    "- choose the Class **Ci** that has max probability\n",
    "\n",
    "**Side note**:  \n",
    "Since **Prob(D)** is constant, we can ignore the denominator part and just focus on the numerator's products.  \n",
    "\n",
    "So, all we are doing is:  \n",
    "\n",
    "Choose class **Ci** according to argmax{ Prob(Ci | D) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noob documents for training :P\n",
    "spam = [\n",
    "    \"you have won a lottery\",\n",
    "    \"congratulations! you have a bonus\",\n",
    "    \"this is bomb\",\n",
    "    \"to use the credit, please click the link\",\n",
    "    \"thank you for subscription. please click the link\",\n",
    "    \"bomb\"\n",
    "]\n",
    "Y_spam = [1 for i in range(len(spam)) ]\n",
    "\n",
    "non_spam = [\n",
    "    \"i am awesome\",\n",
    "    \"i have a meeting tomorrow\",\n",
    "    \"you are smart\",\n",
    "    \"get me out of here\",\n",
    "    \"call me later\"\n",
    "]\n",
    "Y_non_spam = [0 for i in range(len(non_spam)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2)).fit(spam + non_spam)\n",
    "X_train_vectorized = count_vectorizer.transform(spam + non_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Model\n",
    "model = MultinomialNB(alpha=0.1)\n",
    "model.fit(X_train_vectorized, Y_spam + Y_non_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"call you\",\n",
    "    \"you have won\"\n",
    "]\n",
    "predictions = model.predict(count_vectorizer.transform(documents))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# convert to pandas dataframe for seamless training\n",
    "spam_df = pd.DataFrame(spam, columns=['text'])\n",
    "spam_df['target'] = 1\n",
    "non_spam_df = pd.DataFrame(non_spam, columns=['text'])\n",
    "non_spam_df['target'] = 0\n",
    "\n",
    "# final data\n",
    "data = pd.concat([spam_df, non_spam_df], ignore_index=True)\n",
    "data\n",
    "\n",
    "# feature extraction\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2)).fit(data['text'])\n",
    "X_train_vectorized = count_vectorizer.transform(data['text'])\n",
    "model = MultinomialNB(alpha=0.1)\n",
    "model.fit(X_train_vectorized, Y_spam + Y_non_spam)\n",
    "documents = [\n",
    "    \"call you\",\n",
    "    \"you have won\"\n",
    "]\n",
    "predictions = model.predict(count_vectorizer.transform(documents))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do real training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5572\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Go until jurong point, crazy.. Available only ...       0\n",
       "1                      Ok lar... Joking wif u oni...       0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...       1\n",
       "3  U dun say so early hor... U c already then say...       0\n",
       "4  Nah I don't think he goes to usf, he lives aro...       0\n",
       "5  FreeMsg Hey there darling it's been 3 week's n...       1\n",
       "6  Even my brother is not like to speak with me. ...       0\n",
       "7  As per your request 'Melle Melle (Oru Minnamin...       0\n",
       "8  WINNER!! As a valued network customer you have...       1\n",
       "9  Had your mobile 11 months or more? U R entitle...       1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load training set\n",
    "data = pd.read_csv('data/spam.csv')\n",
    "\n",
    "data['target'] = np.where(data['target']=='spam',1, 0)\n",
    "print(len(data))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4179,), (1393,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(spam_data['text'], \n",
    "                                                    spam_data['target'], \n",
    "                                                    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4179, 40704)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract features\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2)).fit(X_train)\n",
    "X_train_vectorized = vectorizer.transform(X_train)\n",
    "X_train_vectorized.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create Naive Bayes model\n",
    "model = MultinomialNB(alpha=0.1)\n",
    "model.fit(X_train_vectorized, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9708270376721049"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate True Positive Rate vs False Positive Rate\n",
    "predictions = model.predict(vectorizer.transform(X_test))\n",
    "score = roc_auc_score(Y_test, predictions)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1193.    3.]\n",
      " [  11.  186.]]\n",
      "Recall for Spam:\n",
      "0.970827037672105\n",
      "Precision for Spam:\n",
      "0.9874953857511997\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f80dfec9898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create custom confusion matrix for evaluation\n",
    "result = {}\n",
    "cm = np.zeros((2, 2))\n",
    "precisions = np.zeros(2)\n",
    "recalls = np.zeros(2)\n",
    "for t, p in zip(Y_test, predictions):\n",
    "    cm[t][p] += 1\n",
    "\n",
    "tp = np.diag(cm)\n",
    "fn = np.sum(cm, axis=1) - tp\n",
    "fp = np.sum(cm, axis=0) - tp\n",
    "\n",
    "for i in range(2):\n",
    "    p_denom = tp[i] + fp[i]\n",
    "    r_denom = tp[i] + fn[i]\n",
    "    precisions[i] = 0 if p_denom == 0 else tp[i]/p_denom\n",
    "    recalls[i] = 0 if r_denom == 0 else tp[i]/r_denom\n",
    "    \n",
    "# calculate from sklearn\n",
    "fpr_, tpr_, _ = roc_curve(Y_test,  predictions)\n",
    "#tpr = cm[1][1] / (cm[1][1] + cm[1][0])\n",
    "tpr = recalls[1]\n",
    "fpr = cm[0][1] / (cm[0][1] + cm[0][0])\n",
    "\n",
    "precision = np.average(precisions)\n",
    "recall = np.average(recalls)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Confusion Matrix:\\n{}\".format(cm))\n",
    "print(\"Recall for Spam:\\n{}\".format(recall))\n",
    "print(\"Precision for Spam:\\n{}\".format(precision))\n",
    "\n",
    "plt.plot(fpr_, tpr_, label=\"spam, auc=\"+str(score))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_docs = [\n",
    "    \"you have won a lottery\",\n",
    "    \"click the link\",\n",
    "    \"i have a meeting\"\n",
    "]\n",
    "predictions = model.predict(vectorizer.transform(test_docs))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
