{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lt83/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n",
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Autoencoder\n",
    "\n",
    "We all know what PCA (Principal Component Analysis) is. All PCA does is nothing but find an optmial hyperplane where higher dimensional data can be projected onto, in order to reduce the dimension of the original data. Normally, that hyperplane is along the eigen vector. It requires some old-school mathematics to do so.\n",
    "\n",
    "However, same can be done using neural networks to reduce the dimension as well as encode a higher dimensional data into lower dimensional features. Such technique is called **Encoding**.  \n",
    "\n",
    "The reverse of encoding is **decoding**.\n",
    "\n",
    "\n",
    "### Example\n",
    "Say we have an image **64 X 64**.  \n",
    "\n",
    "Number of pixels = 4096  \n",
    "Number of channels = 1 (for simplicity)\n",
    "\n",
    "When we try to create a model for image with such (relatively) huge number of pixels, the machine learning model will be computationally expensive. So, we encode the pixels for further usage. Further usages can be:\n",
    "- image labelling\n",
    "- image captioning\n",
    "- semantic segmentation\n",
    "- ...\n",
    "\n",
    "### Architecture\n",
    "The architecture that **encodes** and **decodes** is **autoencoder** - as simple as that. :D\n",
    "\n",
    "**Encoder**\n",
    "- flatten the original image -> 2d to 1d\n",
    "- Add neural network layers (dense)\n",
    "- This dense layer's size is our encoding code size\n",
    "\n",
    "**Decoder**\n",
    "- accept a 1d vector -> encoded vector\n",
    "- add a dense layer equal to the size of original image (including the number of channels)\n",
    "- Hence, we get original image\n",
    "\n",
    "Although we can technically compress an image (or remove irrelevant features - in case of image, pixels), \n",
    "the reconstruction is lossy. While encoding the image, we lose certain information that the decoder will never recover.\n",
    "So, our best effort lies in minimizing such reconstruction error.\n",
    "\n",
    "So, an autoencoder is nothing but a neural network as:\n",
    "\n",
    "input -> encoder -> [encoded output] -> decoder -> [decoded output as near to the input]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_pca_autoencoder(img_shape, code_size):\n",
    "    \"\"\"\n",
    "    Here we define a simple linear autoencoder as described above.\n",
    "    We also flatten and un-flatten data to be compatible with image shapes\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder = keras.models.Sequential()\n",
    "    \n",
    "    # accept image\n",
    "    encoder.add(L.InputLayer(img_shape))\n",
    "    \n",
    "    # flatten pixels\n",
    "    encoder.add(L.Flatten())\n",
    "    \n",
    "    # add a dense layer to encode the pixels\n",
    "    encoder.add(L.Dense(code_size))\n",
    "\n",
    "    decoder = keras.models.Sequential()\n",
    "    # accept encoded input\n",
    "    decoder.add(L.InputLayer((code_size,)))\n",
    "    \n",
    "    # add a dense layer equal to original image (with channels)\n",
    "    decoder.add(L.Dense(np.prod(img_shape)))\n",
    "    \n",
    "    # reshape as 2d image (h, w, c)\n",
    "    decoder.add(L.Reshape(img_shape))\n",
    "    \n",
    "    return encoder,decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
